{
    "summary": "이번 회의는 최종 프로젝트 발표와 기말 시험에 관한 중요한 사안들을 다루기 위해 소집되었습니다. 회의 초반, 팀 프로젝트의 최종 발표 일정이 확정되었고, 다음 주 일요일인 12일까지 제출을 한 후, 11일에 우수 작품 발표가 이루어질 것이라는 안내가 있었습니다. 발표과제에 대해서는 팀원 소개와 함께 프로젝트의 주제를 명확히 설명하고, 결과물의 제한점을 기술할 것을 강조하며, 발표 내용의 질과 관련된 기준도 공유되었습니다. \n\n회의 중, 기말 시험의 내용과 방식에 대해 상세히 설명하면서 평가 기준이 기존과는 다르게 설정될 것임을 예고했습니다. 교수는 학생들에게 기말 시험에서의 학습 방향과 유의사항을 강조하며, 특히 기초 이론보다는 실무에서의 적용 가능성을 중시할 것을 권장했습니다. \n\n또한, 교수의 임시 대리로서 향후 과목 개설에 대한 계획을 소개하고, 피드백을 통해 개선점을 지속적으로 반영할 것이라며 자신이 맡게 될 과목의 방향성과 비전을 나누었습니다. 회의의 마지막에서는 학기 동안의 학습이 향후 취업에 긍정적인 영향을 미칠 것이라는 격려와 함께 학생들에게 성실함과 책임감을 가지고 수업에 임해줄 것을 당부하며 마무리되었습니다. \n\n결국, 최종 발표는 정해진 일정에 따라 진행되고, 기말 시험에서도 새로운 접근 방식이 제시될 것이며, 교수는 학생들에게 피드백을 통한 소통의 문을 열어두어 향후 가능성을 다질 것을 약속함으로써 회의가 종료되었습니다.",
    "keywords": [
        "AI분석",
        "Pipeline",
        "Async"
    ],
    "action_items": [
        "최종 발표 자료 제출 (담당: 학생들, 기한: 2023-12-12)",
        "과제 발표 영상 공유 (담당: 학생들, 기한: 2023-12-12)",
        "기말 시험 학습 내용 정리 (담당: 학생들, 기한: 2023-12-18)",
        "피드백 양식 제출 (담당: 학생들, 기한: 2023-12-12)",
        "출석 사유 제출 (담당: 결석한 학생, 기한: 2023-12-11)"
    ],
    "suggestions": [
        "최종 발표를 위해 시간 관리 철저히 할 것",
        "기말 시험 준비를 위해 매주 수업 내용을 복습할 것",
        "동료들과의 협업을 통해 발표 자료의 퀄리티를 높일 것"
    ],
    "sentiment": "Neutral",
    "raw_json": [
        {
            "task": "최종 발표 자료 제출",
            "assignee": "학생들",
            "due_date": "2023-12-12",
            "priority": "Critical",
            "reasoning": "최종 발표 자료를 제출해야 하며, 제한된 시간 내에 제출해야 성적 평가에 포함됨"
        },
        {
            "task": "과제 발표 영상 공유",
            "assignee": "학생들",
            "due_date": "2023-12-12",
            "priority": "High",
            "reasoning": "발표 피드백을 받고자 하는 학생들은 영상 공유게시판에 과제를 올려야 함"
        },
        {
            "task": "기말 시험 학습 내용 정리",
            "assignee": "학생들",
            "due_date": "2023-12-18",
            "priority": "High",
            "reasoning": "기말 시험의 감소형 과목 내용에 대한 준비가 필요함"
        },
        {
            "task": "피드백 양식 제출",
            "assignee": "학생들",
            "due_date": "2023-12-12",
            "priority": "Medium",
            "reasoning": "과목에 대한 피드백을 수집하여 차기 과목 개선에 반영함"
        },
        {
            "task": "출석 사유 제출",
            "assignee": "결석한 학생",
            "due_date": "2023-12-11",
            "priority": "Low",
            "reasoning": "결석 사유가 있는 학생은 서류를 제출하여 감점을 피해야 함"
        }
    ],
    "raw_script": "그리고 남은 이제 발표 한 프로젝트에 대해서도 얘기를 할 거고요. 잠시만요. 공지가 좀 많이 올라왔거든요. 공지를 보시면 3개가 올라왔습니다. 선 프로젝트 벌써 이제 최종 발표가 됐습니다. 그래서 아마 12월 7일까지 이번 주까지가 될 것 같고요. 그리고 제가 요청이 왔는데 API 지금 못 드린 분도 계신 것 같은데요. 혹시 지금도 아직 좀 필요하시다면 저한테 수업 끝나고 찾아와 주시면 감사하겠고요. 12일 일요일에 이제 다 밤 11시 59분까지 제출하시면 됩니다. 한 10분 정도 늦는 거는 제가 다 봐드렸어요. 10분 한 30분 정도 늘릴 수 있는 거는 다 봐드렸고 제가 월요일에 딱 이제 오전에 됐을 때 여러분들 파일을 다 다운받아 가지고 제가 평가를 하게 되고 거기서 이제 우수 작품을 11일에 발표를 할 것 같습니다. 지난번에는 제가 9팀을 선정을 했는데 이번에는 조금 더 적게 선발을 할 예정입니다. 그래서 한 6개 팀을 선발을 할 예정이고 그리고 만약에 내가 선발이 안 됐는데도 피드백이 궁금하다라고 하시는 분들은 여기다가 이제 발표 영상 공유 게시판에 여기다가 다 이제 과제를 올려주세요. 그러니까 여러분들이 제출하실 때 이 과제도 제출을 하셔야 되고요. 이 최종 결과에도 제출하시면 제가 다운 받아가지고 여러분들 이제 성적 이제 채점할 때 여기서 볼 것 같고 그런데 이제 모든 사람들이 다른 팀에서 뭐 하는지 궁금하다라는 거는 이제 공유 게시판에다가 여기다 글을 올려주세요. 아마 여기 파일이 올라가는 건데요. 이 제한이 있으니까 용량 너무 크게 하시면 안 될 것 같고 그리고 어떤 분들은 이제 유튜브에 업로드하신 다음에 링크만 올리시는 분들 그런 것도 되게 좋은 것 같습니다. 이렇게 해서 이제 최종 결과 를 해 주시면 되고 최종 결과에는 어떤 내용이 들어가야 되느냐 여러분들이 처음에 팀원 소개하고 주제 발표하는 거 많이 하셨잖아요. 이제는 여기 제가 빼먹었네요. 2차 때 했던 거랑 동일하게 프로젝트 주제가 어떤 역할을 했는지를 소개를 해 주세요. 1인 팀이 아니라 2인 3인 팀들은 여기다가 이제 무엇을 했는지를 각자 소개를 잘 해 주셔야 됩니다. 제가 팀원들을 평가할 때 그걸 고려를 할 겁니다. 그래서 생강명 2명 팀원 역할 소개는 해 주셔도 됩니다. 만약에 변경 사항이 없다고 하면은 중간 발표 때랑 똑같이 그냥 역할 해 주시면 되고요. 서론의 원래 동기 이걸 해야 되는 필요합니다. 중요합니다를 중간 발표 때도 다 얘기를 해 주셨죠 근데 변경이 없다면 패스하셔도 되고요. 중간 발표랑 나는 많이 변경이 됐어요. 방향성이 많이 바뀌었어요. 하시는 분들은 이 동기나 이거에 대한 인터뷰도 해 주시면 감사하겠고 그리고 핵심 내용은 이제 무조건 들어가야 되고 이제 이 마지막 최종 발표의 핵심은 이제 데모 데모를 보여주시거나 영상을 이제 촬영을 하시거나 혹은 내가 연구적인 걸 했다고 하면은 실험 결과 비교 실험 결과를 추가를 해 주시고 현재 서비스에 여러분들이 만드신 거 자체가 바로 시장에 나갔을 때 다 잘 되는 게 당연히 아닐 거잖아요. 그래서 여러분들이 생각하시기에 이것의 현재 제한점을 같이 서술해 주시면 되겠습니다. 데모랑 제한점을 같이 얘기해 주셔도 되고요. 혹은 실험 결과를 보여주면서 아직 이런 건 잘 되는데 이런 건 안 됩니다라고 하는 제한점을 잘 얘기해 주셔야 됩니다. 그래서 여러분들이 다른 데 갈 때도 이런 발표 같은 자리가 있을 때 어떤 자리에 가면은 여러분들이 과하게 홍보를 할 수가 있겠죠. 이거는 다 너무 좋은 겁니다. 이런 자리가 있을 것 같고요. 근데 저희 수업에서는 내가 안 되는 지점을 정확하게 스스로 아는지까지가 평가 요소라고 보시면 되겠습니다. 그리고 향후에는 이런 식으로 발전하면은 되게 잘될 것 같아요를 해 주시면 좋을 것 같아요. 이게 첫 번째 공지 사항이었고요. 두 번째는 기말 시험입니다. 저희가 다다음 주 이제 11일에 최종 발표를 하게 되고 18일에 기말고사를 봅니다. 그래서 오늘 기말고사의 어떤 내용을 공부하시라를 얘기를 드릴 것 같아요. 여러분들이 이제 이 대학교에서 어떤 수업을 하고 강의를 듣고 하는 게 지적인 그런 흥미를 느끼는 것도 있지만 결국은 성적이 남게 되잖아요. 그래서 불행하게도 우리는 여러분들은 학점에 대한 관리를 하셔야 되고 나중에 취업을 하시거나 유학을 가시거나 어쨌든 그 학점을 결국 요긴하게 쓰셔야 될 것 같아요. 그래서 그걸 위해서 저는 평가를 해야 될 것 같고 이 시험을 봅니다. 근데 이제 제가 이 수업에서는 이론을 더 깊게 알려주거나 수학적인 원리 이런 걸 알려주는 수업이 아니기 때문에 이 기말 시험은 좀 그런 이제 다른 시험들과 좀 다르게 낼 거긴 한데 그거를 좀 이따가 PPT를 보면서 알려드릴게요. 그래서 전체 처음부터 끝까지 다시 한 번 훑어가면서 이런 내용 공부하시라를 제가 요약을 해드리겠습니다. 마지막으로 피드백을 주시면 감사하겠습니다. 그래서 피드백 제가 이거를 양식을 만들어 놨는데요. 제가 사실 소프트웨어 응용 과목을 전담하는 교수는 아닙니다. 원래는 황일수 교수님 과목이고요. 황일수 교수님이 연구년 가시면서 한 학기 연구년 가시고 아마 내년에 돌아오시는 것 같은데 제가 임시로 맡게 됐습니다. 그래서 원래는 저는 이제 내년부터는 세 과목을 항상 전담을 할 것 같아요. 첫 번째로 기초 과목은 머신 러닝 과목을 이제 내년 2학기에 열 겁니다. 아마 여기 계신 분들 졸업하실 수도 있을 것 같은데 머신 러닝 기초 이론을 먼저 첫 번째를 다룰 것 같고요. 그다음에 자연어 이해 및 생성을 두 번째로 다룰 겁니다. 그리고 마지막으로 딥러닝 실제어 응용 과목을 다룰 거예요. 그래서 그 과목이랑 사실 소프트웨어 응용이랑 되게 비슷하게 제가 설계를 했는데요. 그래서 여기 계신 분들이 제 과목 소프트웨어 응용을 잘 들어주셨는데 다음 학기에 제가 딥러닝 실제 응용을 열 것 같거든요. 그래서 여러분들은 이미 제 수업을 들으셨기 때문에 굳이 그 과목을 들을 필요가 없습니다. 그래서 그 과목을 최대한 시청 안 해 주시고 안 되는 분들을 위해서 남겨주시면 감사하겠고 굳이 나는 똑같은 과목을 또 들어오겠다라고 하면은 저한테 해명을 하거나 어떤 이유 때문에 들어야 된다라는 메일을 보내셔야 됩니다. 그렇기 때문에 요 과목의 피드백은 딥러닝 실제와 응용 과목을 제가 할 때 여러분들의 피드백을 잘 반영을 하도록 할게요. 그래서 여기 내용은 그냥 이제 1점부터 5점까지 이거를 해 주시는 거는 괜찮아 여러분들 생각대로 해 주시고 사실 저한테 도움이 되는 부분은 이게 어떤 피드백이 있는지 한 프로젝트가 어땠는지에 대한 내용 개선 방향 이런 게 되게 중요한 것 같고요. 그리고 사실 이 수업뿐만 아니라 여러분들이 저한테 공유하고 싶은 사항이 있다. 컴퓨터 과학부가 이렇게 돼야 됩니다. 이런 사항들 있잖아요. 그런 것들 수업 외적인 것들을 건의 사항 주시면은 제가 최대한 반영을 하도록 할게요. 그래서 저도 이제 벌써 이제 학교에 온 지 3학기가 지나고 있는데 어쨌든 제가 약간 어떻게 보면 막내 교수잖아요. 다른 교수님들 나이가 많으시고 그래서 제가 어쨌든 건의하고 이런 식으로 합시다 이런 것들이 이제 젊은 교수들의 입장이 의견이 되게 많긴 하거든요. 그래서 이런 것들을 잘 작성해 주시면은 제가 그런 기회가 있을 때마다 그런 의견을 목소리를 내도록 하겠습니다. 그리고 또 하나는 여러분의 강의 평가 하시잖아요. 그래서 이거 말고 강의 평가를 학교에서 이제 성적표 보려면 그전에 하시잖아요. 그런 것도 이제 성실히 해 주시면 감사하겠습니다. 그러니까 이제 성실이라고 하는 것은 저를 좋게 평가해 달라는 게 없는데 막 그냥 점수를 높게 달라는 거라기보다는 제가 그런 거에서 잘 가르쳐 왔더라라고 이제 판별이 되면은 저희 이제 교육으로서의 약간 제 목소리에 힘이 더 실어질 것 같아요. 그래서 만약에 내가 성적을 보기 위해서 그냥 그냥 아무거나 막 누르지 말고 제 수업이 좋았다면 높은 점수를 주시고 별로였다면은 거기다 피드백을 달아서 주시면 감사하겠습니다. 그것이 저한테는 큰 힘이 될 것 같고요. 그리고 네 그리고 다시 돌아와서 그 성적 같은 경우는 제가 여러분들 일요일 것까지 다 지금 채점을 하고 이제 매겨서 그걸 드릴 것 같아요. 그래서 제가 제 기준은 우수 발표를 하셨던 분들은 일단 3개 등급으로 상중하로 나눌 거고요. 우수 발표를 하셨던 분들은 다 상이라고 생각하시면 됩니다. 그래서 상이고 발표를 안 하셨던 분들 중에서도 상중하로 제가 또 나눌 수가 있고요. 그리고 하라는 기준은 사실 정말 한 게 별로 없는데 그냥 GPT 써가지고 대충 제출만 한 경우 이런 것들이 딱 눈에 보이거든요. 그런 경우는 이제 하를 받게 됩니다. 그리고 그 세 번의 발표를 다 합산을 해서 점수가 나가게 되고요. 그리고 수업 중간중간에 발표를 해 주셨던 분들은 제가 이 다 합산을 한 점수 100점에서 한 번 발표했다 그러면 1점이나 2점을 추가 점수를 드렸습니다. 그리고 그렇게 보면은 그게 이제 작은 점수일 것 같지만 사실 그 등급 간에 플러스냐 제로냐 이거를 이제 가릴 수 있는 기준이 될 수 있을 것 같고요. 그리고 제가 걱정되는 분들은 수업에 출석을 너무 안 하셨던 분들이 한 두 분 정도 계셨던 것 같아요. 그래서 그 두 분은 만약에 여기 계신지 안 계신지 오늘도 안 오셨는지 모르겠지만 출석을 4회 이상 하셨다라고 하면은 감점이 이제 크게 크게 들어갑니다. 근데 내가 4회 이상을 결석을 했는데 다 이유가 있는 거였다. 서류로 변환할 수 있다라고 하면 저한테 보내주세요. 그래서 저는 어떤 생각을 가졌었냐면 원래는 여러분들 대학생이고 이제 책임을 질 수 있는 나이잖아요. 그래서 저는 수업에 출석 체크를 막 이렇게 일일이 해가지고 열심히 해가지고 여러분들이 이 자리에 굳이 앉힌다는 것이 무슨 의미일까 이런 생각을 많이 했던 것 같아요. 그래서 출석에 대한 거를 이렇게 3회까지는 무단 결석을 하셔도 감점이 전혀 없는데요. 근데 3회 이상 그리고 수업에 대부분을 결석하신 분들은 교칙도 있는 것 같고 그분들은 이 수업을 통해서 성실하게 수행을 하지 않으신 분들이기 때문에 강점을 줄 수밖에 없어 라고 생각하시면 될 것 같습니다. 그 성적은 제가 여러분한테 드릴 수 있는 그것에 최대한 잘 드리려고 노력을 하겠습니다. 근데 이제 상대평가이기 때문에 b 플러스까지가 b 플러스 맞나요? 70%인가 60%인가 그 기준이 있어요. 그래서 학교에서 정한 기준을 채워서 제가 최대한 드리겠다라고 말씀드리고 싶습니다. 성실히 하셨으면 a 이상 근데 60%까지는 잘라야 되긴 하는데 최대한 b 플러스는 최대한 안 드리고 그래도 이제 한 분 경계만 딱 드리고 나머지는 a로 드리고 싶고 이런 방어입니다. 그래서 프로젝트를 여러분들이 저는 개인적으로 생각했을 때 되게 잘 수행을 해 주신 것 같아요. 그래서 마무리만 딱 잘 지으면 저는 이 과목을 했을 때 되게 만족감을 느낄 것 같고요. 그러면 마지막 소감은 이거 수업 끝날 때쯤 다시 드리도록 할게요. 아직 다음 주가 있긴 한데 그래도 오늘 이런 얘기를 최대한 하는 게 좋을 것 같아서 돌아와서 이제 2주 차부터 PPT를 보고 알려드리도록 할게요. 2주 차에서 이런 트렌드 같은 얘기를 했는데 이런 트렌드에서는 여러분들 공부하실 게 별로 없죠. 그냥 제가 말했던 거 이해만 하시고 그냥 쭉쭉 넘기시면 됩니다. 과거에는 이런 기술들이 있었다. 기술 소개 같은 것들 이런 것들은 사실 암기할 거리는 없고 제가 했던 말을 드렸던 걸 이해를 하시면은 그렇게 무리는 없을 것 같고요. 그리고 쭉쭉쭉 넘겨서 어떤 거를 공부하시면 되냐 이제 여기 이제 랭귀지 모델 이런 것도 지난 수업 때 열심히 했던 내용이에요. 이런 수식을 암기해야 되느냐 암기 안 하셔도 됩니다. 엠비즈 모델 다음 확률을 계산하는 거 계산 문제가 안 나옵니다. 근데 여기서 핵심은 결국 이제 AI 모델들이 뭘 하느냐 결국 이 통계적인 모델이나 룰 기반의 모델과 다르게 이런 게 이제 빵점 통계 기반이라고 하면 빵이라고 하는데 그리 랭귀지 모델은 이거를 채워 넣을 수 있다는 장점이 있죠. 그 머신 러닝 AI 모델 딥러닝 모델 엔비즈 모델들은 예측하는 능력 일반화 능력이 있게 됩니다. 이런 것들을 대략적으로 아시면 될 것 같고요. 그래서 왜 잘 되는지 컴플렉션과 제너럴라이제이션에서 장점이 있습니다라고 제가 소개를 드렸고요. 그리고 언어 모델이 하는 것이 정보를 압축을 하는 것인데 이 압축하는 과정에서 어떤 문제가 발생한다 이런 방향 흐름을 이해를 하시는 게 되게 중요합니다. 그래서 세상에 있는 정보 지식이 굉장히 다양한데 어떤 거는 배우지 말아야 할 것들이 있고 배웠는데 내가 잘 못 배운 압축을 잘 못한 것들이 있게 됩니다. 그러면서 AI 모델에 큰 문제가 발생을 하게 됩니다. 그래서 이런 것들 잘 기억해 두시고 그래서 문제가 제가 설명을 드린 중대한 문제가 무엇이냐 1번은 헬류시네이션 헬류시네이션도 사실 엄밀히 보면은 되게 모호한 용어이긴 해요. 근데 어쨌든 제가 얘기드린 수업 시간에 드린 것처럼 이제 사실적인 정보에 대한 실수 오류 그거를 위배하는 게 하루 시네이션이라고 얘기 드렸고 그리고 최신 지식에 대한 시간성에 대해서 일반화를 못하는 거, 과거 데이터를 학습했는데 현재 데이터 그러니까 지식이 계속 변하고 새로 발생하는 그런 새로운 것들에 대해서는 내가 잘 대답을 하지 못하는 거 이런 것들이 가장 중대한 문제라고 얘기해도 되겠죠. 문제는 이 두 가지인데 이 뒤에 흐름에서 나오면은 이 각각의 문제를 어떻게 해 어떠한 기술로 해결할 수 있는지가 이제 시험에 제가 매 부분입니다. 그래서 이 그림 같은 것들도 제가 설명을 드렸는데 이 오른쪽에 있는 이 이 퍼플렉시티라고 하는 값이 이제 로스와 상관관계가 있는 수치이고 이것이 높으면 높을수록 에러가 높다고 설명을 드렸어요. 그래서 옛날 데이터부터 최근 데이터로 가면서 이 로스가 점점 높아진다. 퍼플리스트라고 하는 값이 높아지니까 2017년까지 학습한 모델로 2019년 9월 거를 하면은 제가 뉴스에 대해서 잘 대답을 하지 못한다라고 설명을 드렸습니다. 그리고 이런 것도 시간에 따라 변하지 않는 지식 변하는 지식 새로 등장하는 지식 이런 거에 따라서 이 케이스에 따라서 최근 지식을 다 못하고 바뀌는 데이터를 잘 못하는 이런 것들 어떻게 보면 좀 상식적인 수준이라고 볼 수도 있겠네요. 그래서 이걸 해결하기 위해서 리티리벌 어그멘티드 제너레이션 레그 혹은 비티벌 어그멘티드 LRM 같은 기술들이 나왔다. 그런 소개를 드렸고 이제 이거 어떻게 시 예시가 이런 식으로 흘러가는 것들 이런 건 예시는 볼 필요는 없겠네요. 넘어가고 아마 3장에서 이거에 대한 설명을 더 깊게 했던 것 같습니다. 그래서 이 두 가지 문제를 어떻게 해결하느냐 레그 기술을 통해서 한다. 검색 엔진을 같이 사용해서 그 정보를 가지고 온다 이렇게 세 단계로 이루어진 그런 파이프라인도 아시면 좋을 것 같고요. 그래서 레그 기술에 대해서 제가 2개의 파트로 설명을 드렸어요. 그래서 레벨 기술을 하려면 결국 검색 능력이 좋아야 된다. 그래서 검색 파트가 하나 있고요. 검색을 한 다음에 그 뒤에서 에러램을 갖다 붙였을 때 어떤 문제가 더 발생하는지가 두 번째 파트였습니다. 이렇게 쭉 넘어가고 검색 파트에서는 과거의 검색부터 현재 여기도 이제 지금은 지금 나와 있는 대화형 검색 그래서 이런 흐름이 있었고요. 그리고 여기서 제가 이 세 가지 크롤링 인덱싱 랭킹에 대해서 얘기를 했는데 크롤링에 대해서는 제가 얘기를 열심히 안 드렸던 것 같고 인덱싱이랑 랭킹에 대해서는 열심히 얘기를 드렸던 것 같아요. 그래서 인덱싱은 단어 레벨로 이렇게 잘라가지고 미리 이 문서를 다 이렇게 인덱싱을 테이블 형태로 해놓고 키워드 레벨에 검색을 할 수 있다라는 얘기를 했었고, 키워드 레벨의 검색뿐만 아니라 그거를 넘어서는 뉴럴넷 기반 혹은 딥러닝 모델 기반으로 이 쿼리랑 문서 간에 연결을 해주는 기술에 대해서 소개를 해줬습니다. 요 인벌티드 인덱스까지는 볼 필요가 없겠네요. 여기 볼 필요 없고 뒤에 랭킹부터만 보시면 됩니다. 그래서 랭킹을 하는 기술들이 여러 가지가 있는데 그리고 퍼스트 리트리벌이 있고 세컨드 리트리벌이 있다 세컨드 스테이지 리트리벌이 있다. 그래서 퍼스트 리트리벌 혹은 두 번째 거는 리드 랭킹 다시 랭킹하는 두 번째 단계 이렇게 설명을 드렸고요. 또 두 번째 단계에서는 이런 다양한 형태의 뉴럴넷을 쓸 수 있었다라고만 배웠습니다. 근데 이런 아키텍처 제가 그림에 넣긴 했는데 버트는 자연어 시간에 배웠던 분들만 알 것 같아서 이 버트가 뭔지 이런 것들은 제가 안 내도록 하겠습니다. 그래서 이런 것들 쭉쭉 넘어가고 그다음에 여기서 이제 레그 기술을 쓰면은 어떤 장점이 있는가 세 가지 큰 장점이 있다라고 제가 소개를 드렸죠. 세 가지 장점 그리고 이렇게 했을 때 이 레그를 만들 때 어떤 기술적인 문제점 이슈들이 뭐가 있는가에 대해서 얘기를 했어요. 그래서 그 이슈들 번호 제가 넘버링을 했으면은 제가 시험 문제 내기는 되게 수월하겠죠. 1번 철크 어떻게 구성 하나의 컨텍스를 어떻게 자르거나 어떻게 구성을 해야 되는가 그리고 2번 그리고 검색 노이즈에 취약한데 이거는 어떻게 해야 되는가 이런 것들 이런 노이즈가 듣게 되면은 이 언어 모델이 뒤에 답변을 어떻게 하게 돼서 뭐가 문제다라고 발생하는 그 문제점들에 대해서 제가 한 5가지 정도를 소개해 드렸던 것 같아요. 다섯 가지를 소개해 드렸습니다. 그리고 이것들이 이제 앞으로 점점 어떤 식으로 어떤 방향으로 발전하고 있다 이 단순한 레그가 어드밴스드나 모듈러나 아니면 에이전트로 발전하고 있다. 그 발전 왜 발전을 해야 되는지 아까 문제점을 얘기드렸고 어떻게 발전해야 된다는 제가 설명을 열심히 했죠. 그래서 에이전트 레그에 대해서 뭐가 바뀌면 뭐가 좋아지지 이런 것들을 고민을 해보시길 바랍니다. 그게 세 번째 네 번째는 이제 굉장히 긴 테스크 그러니까 시간을 많이 들여서 풀어야 되는 문제 해결형 AI에 대해서 소개를 드렸네요. 이런 것도 제가 문제 내기 좋을 것 같은데 이전까지 오픈 AI가 모델 사이즈를 굉장히 키우면서 GPU를 많이 써가지고 성능을 냈다고 했죠. 근데 이렇게 했을 때 한계가 도달을 했기 때문에 그 한계를 어떻게 돌파했는가가 그 장의 핵심이라고 생각하시면 됩니다. 젠슨 황이 나오면서 이제 테스 타임 스케일링의 시대가 왔습니다. 이렇게 얘기했죠. 그래서 이런 것들은 그냥 단순하게 아시면 될 것 같고 쭉쭉 넘어가서 그래서 리즈닝 LLM 혹은 리즈닝 모델이라고 하는 것들이 나오는데 결국 뭐가 차이가 있지라고 생각하시면 돼요. 간단하게 빨리 얘기드리면 짧게 대답을 하는 애 그리고 생각의 과정에 따라서 더 길게 대답을 하는 애로 압축 요약을 할 수 있을 것 같아요. 근데 길게 어떻게 길게 그냥 단순하게 그냥 쓸데없는 말만 반복하면서 길게 하는 게 아니라 자기가 생각을 하는 것처럼 사람의 생각의 과정처럼 내가 대답을 하는 게 리스닝 모델이죠. 그래서 이런 것들을 제가 물어볼 것 같아요. 딱 이 문제를 낼 것 같아요. 그래서 바로 쇼크웃으로 대답을 하는 게 아니라 시행착오를 겪어가면서 대답을 합니다. 근데 그 시행착오를 겪어가는 과정에 어떠한 LLM da 비어가 있다라고 소개를 드렸어요. 그래서 이렇게까지 실패 지점까지 도달한 다음에 다시 다시 되돌아와서 처음으로 돌아와서 다시 문제를 푸는 거 그래서 길게 풀어야 된다 이렇게 얘기를 드렸고 그때 나오는 생각의 과정들이 몇 가지를 얘기 드렸는데 이런 네 가지의 형태로 중간에 생각을 하더라. 물론 이거 네 가지는 예술입니다. 여러분들이 다섯 번째 예시를 적어주시는데 그게 요즘 나오는 GPT 5에 발견이 된다 그러면 제가 인정을 해드리겠습니다. 그래서 이런 다양한 BA비어가 추론에 녹아 있어서 결국 성능을 올리게 되는 원인이다라고 생각하시면 됩니다. 이게 인지적인 어떤 행동들 비의 예열을 작성을 해놨네요. 그걸 잘 생각해 주시면 될 것 같습니다. 그리고 5장 같은 경우는 이제 앞에서 말했던 4장에서는 랭귀지 모델이 텍스트를 굉장히 길게 생성을 해가지고 수학 문제 코딩 문제 이런 거 잘 푸는 거였거든요. 근데 이제 이 장에서는 텍스트만 가지고 길이를 늘리는 게 아니라 툴을 사용을 해서 추론을 같이 하자 외부 툴까지 이제 에레라한테 쥐어지는 게 결국 저희가 설명드린 설명을 드린 에이전트였습니다. 그래서 이 툴에 대해서 가장 기본적으로 제가 예시를 처음 들었던 건 뭐냐면 리 at라고 하는 연구 모델 이 모델 이름이 리액트거든요. 리액트를 설명을 드렸어요. 여러분들이 처음에 이걸 공부하셔 리액트를 제가 문제를 하나 한 문제 내도록 하겠습니다. 그럼 리액트의 동작 원리 동작 원리를 이해를 해 주세요. 그래서 리액트가 여기까지 설명을 드린 다음에 제가 뒤에서 좀 사례 리액트처럼 이거를 문제를 바꿔서 현재 GPT를 가지고 이거를 제가 예시를 뽑아왔잖아요. 지금 영어로 써 있긴 하는데 문제를 제가 한글로 좀 번역해서 낼까 이런 고민을 하고 있습니다. 그래서 앞에서 이론이 이렇게 이렇게 동작을 한 다음에 이제 프롬프트까지 연결을 해가지고 여러분들이 얘를 해 주세요. 나머지는 쭉쭉쭉 넘기겠습니다. 이런 최근 연구 이런 거 있다 이런 거는 공부하지 마세요. 이런 거는 내가 궁금하다 연구적으로 궁금하다라고 하면은 참고를 하시면 되고 이런 통의 딥 리서치 이런 것도 공부 안 하셔도 됩니다. 그리고 또 마지막 것도 공부 안 하셔도 됩니다. 클로드도 공부 안 하셔도 됩니다. 6장에서는 이제 멀티 모델로 넘어갔네요. 그래서 멀티 모델에서 중요한 거는 제가 컴퓨터 비전 이미지를 인코딩 해가지고 랭귀지 모델에 적용하는 거 알려드렸고 그다음 시간에는 오디오 스피치 데이터를 인코딩을 해서 LM에 적용하는 거를 얘기를 드렸죠. 그래서 여기서 CNN이나 이미지 컴퓨터 비전에 관한 지식을 제가 묻지 않겠습니다. RGB 값이 어떻게 들어가고 이런 거는 저희 수업 시간에 다루지 않았고 CNN 아키텍처 당연히 나오지 않습니다. 이런 것들 제가 소개를 드렸지만 이거는 제가 인공지능 시간이나 다른 시간에 다루도록 할게요. 그래서 쭉쭉쭉 넘어가서 이것들이 결국 이 랭귀지 모델이라고 하는 거에 어떻게 연결을 시킬까 보면은 이제 캡셔닝 이미지 캡셔닝 같은 이 이쪽에서 다뤘던 테스크에 대해서는 알 필요가 있어요. 이미지 캡셔닝이라고 하는 테스크는 이미지가 인풋으로 주어지고 자연어가 아웃풋으로 주어지는 그런 테스크입니다. 그래서 인풋 아웃풋의 구조를 아셔야 되고 그리고 이미지를 인코디더에 넣는데 이제 비주얼 인코더를 사용을 보통 하고요. 얘를 벡터로 바꿔서 벡터나 어떤 토큰 벡터로 바꾼 다음에 랭귀지 모델이 디코더에 넣어주게 되는 원리에 대해서 소개를 드렸습니다. 그리고 클립이나 vit나 베이트 같은 것도 이 기술에 대해서 디테일하게 알 필요는 없습니다. 이렇게 컴퓨터 비전 쪽에서도 사전 학습 s 많이 썼다. 데이터 많이 쓰고 그리고 CNN이 아니라 랭귀지 모델과 같은 아키텍처로 점점 통합되고 있다 이런 것들이 중요한 사항이라고 생각하시면 됩니다. 그리고 이런 것들을 제가 어떻게 문제를 낼지 고민을 하고 있는데 GPT 4로 넘어오면서 이런 재미있는 문제를 학습을 데이터를 열심히 했다. 데이터 같은 것들이 이렇게 이렇게 들어가고 이런 민 같은 것들도 인풋 아웃풋을 어떻게 정리했기 때문에 된다 이런 거를 문제를 내면 좋은데 제가 고민을 해볼게요. 그리고 이 아키텍처는 더 디테일한 내용은 다 아실 필요는 없는데 핵심은 기존의 랭귀지 모델을 활용을 했다는 점이 가장 큰 핵심이에요. 그래서 멀티 모델 특히 컴퓨터 비전도 그렇고 오디오 쪽도 그렇고 이 랭귀지 모델은 기존에 텍스트만 학습한 모델을 그대로 가져와서 사용을 하는데 이 핵심은 이제 비전 인코더 혹은 스피치 인코더를 갖다가 연결을 했다라는 사실이 중요합니다. 그래서 연결을 했는데 수식이 어떻게 되고 이 w라고 하는 뭔가의 매트릭스가 어떻게 되고 이런 것들은 제가 시험에 안 낼게요. 하지만 이렇게 결합을 할 수 있다라는 것을 아시면 될 것 같아요. 결합을 해서 이미지를 하나를 넣었을 때 단어 단어 텍스트에 나오는 단어들 혹은 토큰이라고 부르는 것처럼 이 이미지를 토큰화를 시켰다라는 그 사실이 가장 중요합니다. 이것도 한 문제 내야겠네요. 그래서 단어들처럼 이렇게 비주얼 토큰들을 같이 한꺼번에 연결을 해서 넣었다라고 생각하시면 됩니다. 그리고 또 어려운 복잡한 학습 데이터 이런 이미지에서 이런 답변이 나오는 것들을 열심히 모아서 학습을 했더니 이것들이 잘 되더라 그런 얘기를 드렸고 예시 같은 경우에는 qn 예시를 많이 드렸습니다. 그래서 qn은 이러이러이러한 테스크가 다 가능합니다. 그래서 이런 멀티모달 LLM이 어떤 역할 어떤 테스크들을 수행할 수 있는지를 아시면 될 것 같아요. 이런 모델들 어떻게 학습됐는지는 모르셔도 됩니다. 그래서 여기로 끝낼 것 같고요. 이런 예시들 시험에 캡처할 수 있을지 모르겠네. 이런 다양한 테스크들 이런 거는 내도 좋을 것 같다는 생각이 드네요. 두 장 남았네. 그래도 이 스피치인데 멀티모달에서 여러 개의 어떤 모델리티들이 통합이 되는데 결국 이거에 원리의 핵심은 뭐다 그리고 그 모달리티를 인코딩할 수 있는 인코더가 필요하고 걔네를 단어를 넣는 형태 단어가 이제 단어는 이제 시퀀스 그러니까 토큰들이 이렇게 순차적으로 나오게 되잖아요. 그것들로 변환을 해 줄 수 있으면 멀티 모델이 가능하다. 이것이 핵심 제가 말하고 싶은 핵심이었습니다. 생성 모델은 이런 식으로 이런 아키텍처에 따라서 이거는 이런 거 랭귀지 모델에 이런 데이터 넣으면은 생성까지 할 수 있다. 그러니까 제가 인코딩 단에서 토큰을 변환해야 된다고 얘기했지만 아웃풋 단에서도 이미지를 뭔가 토큰이 나왔을 때 얘를 이미지로 변환할 수 있는 디코더가 있게 되면 이미지를 생성할 수 있다라는 얘기였습니다. 쭉쭉쭉 넘어가서 스피치에서는 이런 게 좀 핵심인 것 같은데 우리가 음성 신호라고 한다면은 음성 신호 안에는 언어적인 내용만 담겨 있는 게 아니다. 그래서 준언어적인 내용 표현 비언어적인 표현 이것들까지 같이 정보가 담겨 있기 때문에 결국 이런 걸 보면은 멀티모달을 늘리는 의의가 이런 데 있는 거죠. 그러니까 나는 음성으로 얘기하는 거 싫으니까 텍스트만으로 얘기할래라고 하면은 그 LLM이 정말 지능적일까라고 생각하면은 준언어적인 내용과 비언어적인 단서를 학습을 못하는 거죠. 그래서 멀티 모달의 핵심은 이런 이 바깥에 있는 영역들 딱 텍스트로 변환되지 않는 그런 시그널들을 받을 수 있고 학습을 하는 것이 핵심이라고 생각하시면 됩니다. 그게 이미지도 마찬가지죠. 이미지랑 이 스피치 쪽에서 랭귀지 모델이 모르는 정보는 뭘까 이런 거 고민해 보시면 되겠습니다. 그리고 qm 이런 아키텍처도 아실 필요가 전혀 없습니다. 이 테스크들은 좀 좀 한번 쭉 보시면 좋을 것 같아요. 이런 예시를 읽어보시면서 이런 음성이 들어갔을 때 이런 아웃풋이 나올 수 있구나 이렇게 생각하시면 됩니다. 그리고 플라밍고 트리로 넘어가겠습니다. 마지막으로 8장은 제가 LLM을 어떻게 학습 실제로 어떻게 발전시켜 나가는지에 대해서 설명을 드릴게요. 여기서는 제가 좀 디테일한 내용을 소개해 드린 것 같아서 그런 것들을 시험 문제를 낼 수는 있을 것 같고요. 지능이 계속 업데이트된다. 그래서 이 네 가지 단계에 따라서 들이 학습이 되고 이제 1번과 2번 위주로 설명을 드렸던 것 같아요. 그래서 3번 4번은 모르셔도 됩니다. 그래서 여기서 핵심은 결국 LLM을 계속 지속적으로 개선하기 위해서는 어떤 일들이 필요한가 어떤 데이터가 필요한가에 대해서 얘기를 드렸던 것 맞습니다. 이거는 사전 학습 셋에 대한 비율 데이터 어떠 어떠한 데이터들이 중요합니다. 웹 페이지 데이터 그리고 대화 데이터 책 뉴스 그리고 과학 데이터 코드 이런 것들이 점점 발전되는 흐름이 이렇게 된다. 근데 여기서는 이제 전처리가 중요하게 되고요. 전처리가 왜 중요한가 수업 시간에 제가 얘기드렸죠. 그리고 대화 데이터가 되게 중요한데 초창기에 이 MVG 모델이 GPT가 나오기 직전에는 이 랭귀지 모델이 이미 있었는데 다양한 테스크들의 데이터를 굉장히 여러 개를 모아서 여기는 10개 10개 20개 정도의 를 모아서 합쳐가지고 학습을 시켰고 그다음부터는 1600개의 테스크 데이터를 다 합쳐가지고 학습을 시켰고 이제 GPT에서는 어떤 테스크가 오더라도 다 이제 다양하게 대화 형태로 수많은 데이터를 모아서 학습을 했기 때문에 이런 멀티 다양한 테스크들을 수행하는 능력이 이런 흐름에 따라서 생겼다라는 걸 제가 얘기하고 싶었고요. 그리고 중요한 게 이제 데이터 디스틸레이션 하는 연구들이나 회사들이 굉장히 많다라고 소개를 했고 이 디스레이션 할 때 그러면은 어떤 데이터가 좋은 것인가에 대해서 얘기를 드렸던 것 같아요. 인스트럭션의 다양성 커버리지가 중요하다. 답변의 정확성 이런 게 중요하다. 그리고 인스트럭션과 리스펀스 간의 정합성 내가 a를 물었는데 b를 대답하면 안 된다 이런 것들을 소개해 드렸죠. 이 세 가지를 중점적으로 좀 이해를 하시고 공부를 하시 하면 좋을 것 같습니다. 그래서 이런 것들을 한 번을 하는 게 아니라 여러 번을 통해서 계속 개선을 해야 된다. 그리고 이제 사람이 데이터를 만드는 시대가 지나갔다라고 얘기 드렸고 에르m이 데이터를 한 개를 뱉는 게 아니라 답변을 한 개를 뱉는 게 아니라 m 게 굉장히 여러 번 뱉는 거예요. 이거의 원리는 무한 원숭이 정리라고 얘기를 드렸고 여기서 중요한 거는 다양한 답변을 다 생성을 한 다음에 이 베리 파이어가 결국 가장 좋은 애를 하나를 뽑아서 내가 더 개선된 데이터다 이 답변을 다시 한 번 에 이 학습시키는 이 개선 루프에 대해서 소개를 드렸어요. 이것도 한 문제 정도 제가 낼 것 같습니다. 그리고 한류 시네이션 팩트 체킹을 할 때 개선은 어떻게 하는가 이거 이거 제가 좀 고민을 해볼게요. 이런 것들도 이런 것들도 아시면 좋겠습니다. 그래서 8장이 끝났고요. 이제 제가 시험 문제는 여러분들이 1시간 이내에 답을 하고 집에 가실 수 있게 되도록 할게요. 그러니까 수학 문제 낸다 그러면 여러분들 막 계산 시간 오래 걸리니까 2시간씩 이렇게 보시잖아요. 제 시험은 그냥 제가 얘기 드린 거 다 이해하시면은 쭉쭉 푸실 수 있을 것 같고 수업 집중만 하셨더라면 100점 하는 데 문제가 없으실 것 같고요. 그리고 알면은 바로 쫙쫙 접어 나가실 것 같고 아예 듣지 않았거나 한 번도 보지 않았으면 답을 하기 어려운 근데 아시면은 그냥 쭉쭉 해서 30분 만에 숨 쉴 수 있게 내는 것을 목표로 갖고 있습니다. 그리고 그래서 기말 시험에서 2시간 30분 이후에 도착하시면 시험을 못 보실 것 같아요. 제가 1시간 시험을 드릴 거라고 예상을 하고 있는데 1시간 보시다가 바쁘신 분들은 30분부터 나가셔도 됩니다. 이렇게 공지를 할 거예요. 근데 나가시는 것부터가 다시 다른 분이 들어오시면 컨닝의 이제 위험이 있잖아요. 이것도 좀 공지를 해드리면 좋을 것 같은데 이제 연세대 고려대 컨닝했다 이런 뉴스가 뜨는데 이게 모든 학교들이 정말 큰 문제인 것 같고 우리나라만 문제가 아니라 미국에서도 엄청나게 그런 사례들이 많다고 하더라고요. 제가 아는 친한 교수님들도 미국에서 시험을 보는데 미국인들도 똑같이 GPT로 커닝을 한다고 합니다. 컨닝을 할 때 몇 가지 패턴들이 있죠. 화장실 간다고 하면서 화장실에서 GPT를 빨리 물어본다든지 이런 게 이제 가장 많이 드러나는 패턴들이고요. 여러분들이 그런 걸 되게 조심하셨으면 좋겠어요. 그러니까 대학생 제가 학교 다닐 때도 컨닝하는 학생이 있었거든요. 그래서 제가 컨닝 하는 학생들이 이제 관찰을 제가 몇 번 했었는데 어떻게 보면은 이게 좀 안타까운 거죠. 내가 어떻게 공부했는지는 중요하지 않아 과정은 중요하지 않은데 학점으로 남기 때문에 나는 어떻게든 컨닝을 할 거야 채팅을 할 거야 이렇게 생각을 하는 게 결국 결과만 딱 보기 위한 거잖아요. 너무 안타깝다고 생각하고 또 한편으로는 이제 AI 시대인데 GPT를 쓰게 해줘야 되는 거 아닌가요? 이런 말들도 있는 것 같아요. 제 개인적인 생각엔 공부를 스스로 해야 되는 그 영역도 분명히 있는 것 같습니다. GPT를 통해서 그냥 딸깍 물어봐서 대답을 하는 그런 영역도 있지만 여러분들이 GPT 없이 도움 없이 처음부터 해야 되는 내용도 그렇게 학습을 해야 되는 것도 분명히 있는 것 같아요. 그래서 여러분들이 제 생각에는 AI의 더 친숙한 여러분들 세대이긴 하지만 채팅을 다른 데 가서라도 정말 하지 말아주셨으면 좋겠고 이런 것들이 발각이 되면은 이제 엄청난 영향과 여러분들이 이 학점을 f 받는 것뿐만 아니라 큰 징계로 이어질 수 있거든요. 근데 어쨌든 저는 여러분들을 믿고 믿는 만큼 믿었을 때는 이제 여러분들을 믿지만 이제 걸렸을 때는 이제 큰 징계가 있을 것 같으니 항상 저 수업뿐만 아니라 어디서든 다 주의하시기 바랍니다. 특히 이제 회사 회사 코딩 테스트 보는데 채팅하시는 분들이 많아졌거든요. 근데 그런 분들을 걸러내면은 회사 당연히 입사 취소가 된다고 합니다. 여러분들이 그런 거 책임감을 가지고 하셨으면 좋겠습니다. 이제 공지는 다 끝난 것 같고 그리고 다음 수업 시간에는 딱 발표하고 끝내야 될 것 같아요. 제가 다음 수업 때 제가 좀 어려운 점은 뭐냐면 자꾸 이제 학교에서 교수를 채용할 때 심사로 들어가야 된다든지 그런 일이 있어가지고 11일에도 수업을 굉장히 길게 하지 못할 것 같고 2시간 다 하고 바로 채용에 들어가야 될 것 같습니다. 그리고 이제 AI 시대에 저는 여러분들이 정부에서도 지금 지원금이 넘쳐나고 있는 것 같아요. 저희 소프트웨어 중심 대학 사업을 하게 돼가지고 강사분들도 다 뽑고 전교생이 내년부터는 코딩 교육 인공지능 기초 강의 다 들어야 된다고 합니다. 이런 게 늘어나는 것 같은데 뭔가 이제 굉장히 괴리가 있어 보이기도 하거든요. 최근에 보니까 딥마인드에서 인턴했던 미국인이 취업을 못 했다 이런 뉴스도 있는 것 같아요. 그래서 그런 사회에서 사람들을 이렇게 뽑는 그거에 대한 수요와 공급, 정부에서 돈을 AI에 투자하는 그 괴리가 있는 것 같거든요. 그럼 이제 제가 여러분들이라면 고민이 많을 것 같아요. 좀 불안하고 어떻게 내 인생 어떻게 해야 되는가 어떻게 설계해야 되는가 이런 고민이 있는데 이 수업을 들으면서 약간 여러분들이 프로젝트 하는 걸 보면서 느꼈던 거는 여러분들이 이미 취직한 기성세대를 이길 수 있는 그 잠재력이 충분히 있을 것 같다라는 생각이 좀 들었던 것 같아요. 그리고 특히 이제 AI API 형태로 되게 막 공급이 되다 보니까 여러분들의 창의성이 조금 더 되게 잘 보이는 것 같거든요. 예전에 이제 제가 수업을 학부생이나 대학원생 때 이렇게 수업을 들었을 때 프로젝트를 하면은 처음부터 끝까지 다 한 명 혹은 3명이 다 만들어야 되기 때문에 기획적인 거를 아이디어를 생각할 것도 없었어요. 그냥 현실적으로 수업이 한 학기 동안 결과물을 낼 수 있는 걸 하자 이렇게 했기 때문에 다들 재미없는 발표를 하고 그랬죠. 근데 여러분들이 하시는 걸 보니까 그 각각의 모듈들은 이미 만들어져 있어 그냥 갖다가 쓸래 근데 갖다가 쓰는데 어떤 결과물을 낼 것이냐에 따라서 되게 이제 흥미롭고 기존에 이제 시장을 이길 수 있는 것들이 나오는 것 같거든요. 요즘 트렌드는 적은 사람이서 큰 임팩트를 낸 게 이제 트렌드예요. 어떤 유튜브에서 이렇게 막 강연 많이 하시는 분들은 그걸 정량 사회라고 얘기하기도 하는데 대기업이나 규모가 큰 데가 오히려 단점인 사회가 있는 것 같거든요. 근데 저도 되게 느꼈고 제 주변의 동료들도 많이 느끼는데 대기업에서 인재들이 굉장히 많이 되고 좋은 서비스 좋은 AI 제품 만들 것 같잖아요. 근데 그렇지 못한 이유는 이 절차가 너무 많아요. 그래서 내가 a를 뭐 할게 내가 혁신적인 걸 할게라고 하면은 반대가 너무 많고 그거를 거쳐야 될 것이 너무 많은 거죠. 특히 이제 대기업에서 저도 일을 해 본 경험을 얘기를 드리면 데이터 라이센스 다 지켰어 어떤 규정 같은 거 다 지켰어 이런 식의 규제들이 엄청나게 많이 있고요. 그리고 혁신적인 걸 한다 그러면 과거 과거 혹은 현재의 데이터를 딱 가지고 와서 나는 현재에서는 그게 시장성이 없을 것 같아 막 이런 이제 태클들이 많이 들어오거든요. 근데 이제 세상이 너무 빨리 변하니까 지금 지금 통하는 비즈니스 모델이 여러분들이 이제 서비스를 만드는 게 넥스트 세대에는 전혀 적용이 안 될 수가 있거든요. 그래서 넥스트까지 같이 생각을 해야 되는데 대기업이나 큰 데는 그런 이제 절차나 그런 태클들이 굉장히 많이 있다. 근데 이제 여러분 대학생이면 내가 규정 지킬 필요도 없고 그다음에 약간 윤리적인 거 이런 거를 벗어나서 창의적으로 이것저것 다 시도를 할 수 있잖아요. 그런 측면에서 굉장히 저 발 빠르고 좀 창의적인 것들이 나왔다고 생각해요. 여러분들이 지금 3학년도 있었고 4학년도 계신데 만약에 여러분들이 취직을 목표로 하신다 그리고 면접을 딱 보신다고 생각하면은 이제 저 같은 사람이 이제 면접관을 하는 거거든요. 면접관을 해서 여러분들이 뭘 하는지를 빠르게 스크리닝을 합니다. 이제 대부분의 사람들이 요즘 또 CV가 다 비슷비슷해요. GPT로 다 이제 하기도 하고 비슷비슷한 프로젝트를 하시게 되는데 그리고 특히 내가 뭔가를 해봤다라고 하는데 깊게 물어보면 모르는 그런 게 너무 많아요. 그래서 여러분들이 그런 거 관리하실 때 이 수업에서 했던 그런 프로젝트처럼 혹은 그걸 더 심화시켜서 한다고 하면은 저는 그거 되게 이제 뽑는 분들한테 되게 매력적일 것 같거든요. 그리고 서비스가 이제 단순하게 그냥 API만 연결하고 프러포즈만 바꿔서 하는 그런 단순한 서비스는 정말 그냥 누구나 할 수 있잖아요. 그냥 요즘은 문과생도 하고 노고디로 다 그런 거 다 하기 때문에 경쟁력이 되게 없어요. 근데 거기서 한 발짝만 딱 나가가지고 여러분들이 수업 시간에 했던 기술적인 요소 되게 저는 depth가 높다고 생각하거든요. 그런 기술적인 거를 문제 해결했던 경험 그런 걸 갖고 계시고 그리고 지금이 딱 풀었던 거를 딱 다음 달에 회사에 취직한다라고 하면 의미가 있거든요. 지금 이번 학기에 열심히 하셨던 게 내년에 가서 취업을 하시거나 6개월이나 1년 뒤에 가면 또 의미가 없어질 수 있어요. 왜냐하면 세상이 너무 빠르게 바뀌기 때문에 그래서 그 최신성을 항상 유지를 하셨으면 좋겠습니다. 그러면은 충분히 저는 경쟁력이 있다고 생각이 들고 이것이 이제 여러분들의 학부생으로서의 돌파구가 아닐까 저는 그런 믿음이 약간 조금 조금씩 생기고 있는 것 같습니다. 그래서 저는 저 나름대로 이제 다음 학기부터도 이제 계속 이런 과목을 개설시켜서 여러분들 후배한테 잘 전달해 드리듯 드리도록 할 테니 피드백 남겨주시고 한 학기 동안 수고하셨고 다음 주까지 제가 얘기를 하고 다음 주에 이제 종강을 하도록 하겠습니다. 그래서 수고하셨고 그리고 산학 프로젝트 하셨던 세 팀은 앞으로 나와 주시고 그리고 API 요청을 하셨는데 제가 답변이 없었던 분도 나와 주시고 다른 분들은 이제 가셔도 될 것 같습니다. 네 수고하셨습니다. 그리고 출석도 혹시 안 하신 분 있으면 알아서 해 주세요.",
    "saved_filename": "음성파일_2025_12_07_21시51분.json"
}